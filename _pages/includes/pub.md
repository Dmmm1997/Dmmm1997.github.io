# üìù Publications 

<!---------------------------------------------------------------------------------------------->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2025</div><img src='images/publications/2024_TPAMI_FGVTP/main.svg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Fine-Grained Visual Text Prompting, in TPAMI, vol. 47, no. 3, pp. 1594-1609, 2025. \\
**Lingfeng Yang**, Xiang Li, Yueze Wang, Xinlong Wang, Jian Yang

[**Paper**](https://ieeexplore.ieee.org/document/10763465)
 | [**Code** ![](https://img.shields.io/github/stars/ylingfeng/FGVP?style=social)](https://github.com/ylingfeng/FGVP)

- Propose joint visual and textual prompt engineering to enhance multi-modal alignment.

</div>
</div>

<!---------------------------------------------------------------------------------------------->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2023</div><img src='images/publications/2023_NeurIPS_FGVP/main.svg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Fine-Grained Visual Prompting, in NeurIPS, vol. 36, pp. 24993-25006, 2023. \\
**Lingfeng Yang**, Yueze Wang, Xiang Li, Xinlong Wang, Jian Yang

[**Paper**](https://proceedings.neurips.cc/paper_files/paper/2023/file/4e9fa6e716940a7cfc60c46e6f702f52-Paper-Conference.pdf)
 | [**Code** ![](https://img.shields.io/github/stars/ylingfeng/FGVP?style=social)](https://github.com/ylingfeng/FGVP)
 | [**‰∏≠ÊñáËß£ËØª**](https://mp.weixin.qq.com/s?search_click_id=10536340093298438394-1705732863737-1260009527&__biz=MzUxMDE4MzAzOA==&mid=2247714099&idx=1&sn=efe4d92ccece149d624d44a19f75404f&chksm=f8982f6663c6f4103967040294490fb7419803ceb6b54f2e79de728104a1858ad03f011d3fb8&scene=7&subscene=90&sessionid=1705732839&clicktime=1705732863&enterid=1705732863&ascene=65&fasttmpl_type=0&fasttmpl_fullversion=7038836-zh_CN-zip&fasttmpl_flag=0&realreporttime=1705732863790&devicetype=android-33&version=28002d3b&nettype=WIFI&abtest_cookie=AAACAA%3D%3D&lang=zh_CN&countrycode=CN&exportkey=n_ChQIAhIQTY3OsEwNdtlJy0RxUEMZyxLcAQIE97dBBAEAAAAAAJ%2F5F8UMLd0AAAAOpnltbLcz9gKNyK89dVj0fDJfc0iQOozTOSv7wroTFtyx6pfMLQW9ACiiUD2XPYTJToJQxVNxvrF5tAIC8R0SbOS35hwJULATy64LUtXxEgmsCoz6Cqv01v%2B25HzaDWybt6vi82M5Lad5HaUdHZAgh4kTKQl9Lri9nQxeptfavWT7F389xOk%2BXh7B4nHuFz%2BeaRdMmZf6lLv3kLpf10%2BJykklCd3SfLyGkE68DPfh1hmFhext2v%2BZTOids%2B0QavnzY7GPOQE%3D&pass_ticket=h3SZ5GzwbdiBvmS547xoTsCldqEAFLvligHaiMY%2BXuAaSiUHNNO2iFTVImHJqOpfAucoZ0LcWe34Hs99pbaVbA%3D%3D&wx_header=3&poc_token=HEYkVWijKQwOws52LqNI8BFkPicAMjsAOeCl7vHt)
 | [**‰∏≠ÊñáËßÜÈ¢ë**](https://www.bilibili.com/video/BV1qw411873s/?spm_id_from=333.999.0.0&vd_source=55bfc02adba971ea9a2c7d47e95180cc)

- Propose fine-grained visual prompt engineering to enhance CLIP's localization accuracy.

</div>
</div>

<!---------------------------------------------------------------------------------------------->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022 Spotlight</div><img src='images/publications/2022_NeurIPS_RM/main.svg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

RecursiveMix: Mixed Learning with History, in NeurIPS, vol. 35, pp. 8427-8440, 2022. (<strong style="color:red;">Spotlight</strong>, Top 12.8%) \\
**Lingfeng Yang**, Xiang Li, Borui Zhao, Renjie Song, Jian Yang

[**Paper**](https://proceedings.neurips.cc/paper_files/paper/2022/file/37e44c4b5321605735be9761f9b758fc-Paper-Conference.pdf)
 | [**Code** ![](https://img.shields.io/github/stars/implus/RecursiveMix-pytorch?style=social)](https://github.com/implus/RecursiveMix-pytorch)


- Propose a simple yet effective mixed-data augmentation technique for image classification.
- Enhance model pretraining performance for object detection and semantic segmentation tasks.

</div>
</div>

<!---------------------------------------------------------------------------------------------->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022 Oral</div><img src='images/publications/2022_CVPR_DynamicMLP/main.svg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Dynamic MLP for Fine-Grained Image Classification by Leveraging Geographical and Temporal Information, in CVPR, pp. 10945-10954, 2022. (<strong style="color:red;">Oral</strong>, Top 3.3%)  \\
**Lingfeng Yang**, Xiang Li, Renjie Song, Borui Zhao, Juntian Tao, Shihao Zhou, Jiajun Liang, Jian Yang

[**Paper**](https://openaccess.thecvf.com/content/CVPR2022/papers/Yang_Dynamic_MLP_for_Fine-Grained_Image_Classification_by_Leveraging_Geographical_and_CVPR_2022_paper.pdf)
| [**Code** ![](https://img.shields.io/github/stars/ylingfeng/DynamicMLP?style=social)](https://github.com/ylingfeng/DynamicMLP)

- Proposed a dynamic MLP fusion framework for fine-grained image classification by incorporating geo-temporal information.
- Improved classification accuracy on multiple fine-grained datasets.

</div>
</div>
